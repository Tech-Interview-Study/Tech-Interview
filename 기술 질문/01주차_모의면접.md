# 추가 질문
- Gradient descent 종류, DL에서는 어떻게 사용되는지  
Gradient descent에서 mini-batch를 주로 쓰는 이유
- Activation function 종류
- DL에서 likelihood가 어떻게 쓰이는지
- 쓰레드가 프로세스 내부에서 어떤 메모리를 공유하는지 (공유안하는 건 왜 그러는지)
- ReLU가 미분 못하는 건 어떻게 해결하는지 알고 있나??  
  - 큰 문제 없어서 일반적으론 0으로 쓴다. x가 0 이하일 경우 다 미분값 0이라 0으로 써도 상관 없을 것 같음.
- ReLU가 왜 비선형인지 
  - 선형성이 없기 때문에 --> 선형성이란 뭔지 설명
- 배열은 정적 자료구조인데 파이썬에서는 배열에 append로 추가가 가능하다. 왜 그런지 설명 가능한가?  
  - [파이썬 배열 구현체](https://seoyeonhwng.medium.com/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%A6%AC%EC%8A%A4%ED%8A%B8-%EB%82%B4%EB%B6%80-%EA%B5%AC%EC%A1%B0-f04847b58286)  
- Data normalization을 PyTorch에서 어떻게 쓰는지

---
# 그 외
- 들어봤는데 모르겠다는 것보다는 그냥 모르겠다고 하는게 좋을것 같다.